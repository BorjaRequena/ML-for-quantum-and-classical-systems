{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "> Training your own language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first practical lesson we saw how to train a language model with the IMDB dataset and how to use it to create movie reviews. Here, we will take a different dataset and do the same process. \n",
    "\n",
    "We will consider the dataset of amazon reviews and compare its outputs with a model trained on the IMDB dataset. In order to speed things up, we will consider sub-samples of both datasets as they contain from $10^5$ to $10^6$ reviews. We will work with $\\sim10^3$ samples on each dataset. \n",
    "\n",
    "This would be quite unreasonable to do if we were not using a pre-trained language model. Since we're fine-tunning the language model, it already knows a lot about English and the world, so a few samples will suffice for the training. If we had to build an entire language model from scratch, we would need quite a lot of text and time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell if running in collab\n",
    "# !pip install -U "fastai<=2.5.0""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie reviews\n",
    "\n",
    "Let's start by training a model to generate movie reviews. In order to spare you a few hours of training, we will work with reduced datasets. However, if you feel brave enough, remove the `_SAMPLE` bit from the cell below and try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                   get_x=ColReader('text'), splitter=RandomSplitter(0.1)\n",
    "                   ).dataloaders(pd.read_csv(path/'texts.csv'), bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always have a look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj pathetic is the word . xxmaj bad acting , pathetic script , xxunk dialog and hip hop music &amp; fashion … what the hell was up with that ? xxmaj the xxunk of this movie acts as bad as the movie he made . xxmaj if someone would have taken some time and effort to xxunk the whole thing , it may of had a chance . xxmaj bet the</td>\n",
       "      <td>xxmaj pathetic is the word . xxmaj bad acting , pathetic script , xxunk dialog and hip hop music &amp; fashion … what the hell was up with that ? xxmaj the xxunk of this movie acts as bad as the movie he made . xxmaj if someone would have taken some time and effort to xxunk the whole thing , it may of had a chance . xxmaj bet the studios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear . xxmaj you 'll love it . \\n\\n xxup xxunk xxbos … you know the rest . xxmaj if you want a good zombie movie , xxup do n't xxup rent xxup this xxup movie . xxmaj if you want a documentary - xxunk look at \" hood life \" you 're at the wrong place as well . xxmaj if you 're looking for a laughable piece of film ,</td>\n",
       "      <td>. xxmaj you 'll love it . \\n\\n xxup xxunk xxbos … you know the rest . xxmaj if you want a good zombie movie , xxup do n't xxup rent xxup this xxup movie . xxmaj if you want a documentary - xxunk look at \" hood life \" you 're at the wrong place as well . xxmaj if you 're looking for a laughable piece of film , this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n take one look at john xxunk ' the thing ' . here we have real xxunk , and gore of eerie proportions . 20 years go by and we get this pile of xxunk xxunk crap ' snakes on a plane ' . when are these people going to wake up and xxunk the xxunk ? special effects are going backwards ! \\n\\n sure you could say .. but the movie</td>\n",
       "      <td>take one look at john xxunk ' the thing ' . here we have real xxunk , and gore of eerie proportions . 20 years go by and we get this pile of xxunk xxunk crap ' snakes on a plane ' . when are these people going to wake up and xxunk the xxunk ? special effects are going backwards ! \\n\\n sure you could say .. but the movie is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good to train our model. Let's fine-tune a language model from wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.335505</td>\n",
       "      <td>4.109118</td>\n",
       "      <td>0.265001</td>\n",
       "      <td>60.892956</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.898440</td>\n",
       "      <td>3.998182</td>\n",
       "      <td>0.273917</td>\n",
       "      <td>54.498997</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.776754</td>\n",
       "      <td>3.986335</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>53.857117</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.592028</td>\n",
       "      <td>3.991039</td>\n",
       "      <td>0.276539</td>\n",
       "      <td>54.111095</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.426960</td>\n",
       "      <td>4.003724</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>54.801830</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_learn.fine_tune(4, base_lr=2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "n_words = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Such terrible acting by Chris Jones is so often disappointing . The story , which has the charm of a classic crime drama , is even worse than the original , which is bad . It 's not enough to be \" the twist \" , where Jones\n"
     ]
    }
   ],
   "source": [
    "stem = \"Such terrible acting\"\n",
    "pred = imdb_learn.predict(stem, n_words, temperature=0.8)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this model is notably worse than the one we saw during the lesson, which we trained with the entire dataset. Here, we're just playing a bit with the concept. \n",
    "\n",
    "In fact, we can check what happens when we start the training from scratch without a pre-trained model in wikipedia (set `pretrained=False`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_learn_0 = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()], \n",
    "                                      pretrained=False).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.964747</td>\n",
       "      <td>6.593917</td>\n",
       "      <td>0.069173</td>\n",
       "      <td>730.637085</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.511461</td>\n",
       "      <td>6.197434</td>\n",
       "      <td>0.080856</td>\n",
       "      <td>491.486481</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.317134</td>\n",
       "      <td>6.088319</td>\n",
       "      <td>0.080856</td>\n",
       "      <td>440.679932</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.208774</td>\n",
       "      <td>6.036022</td>\n",
       "      <td>0.080856</td>\n",
       "      <td>418.226105</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.138093</td>\n",
       "      <td>6.032700</td>\n",
       "      <td>0.080856</td>\n",
       "      <td>416.838806</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_learn_0.fit_one_cycle(5, lr_max=5e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is significantly worse at predicting hte next word (8% accuracy vs 27%). Let's have a look at a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Such terrible acting \n",
      "\n",
      " From have character Meaning i on THE great Looks two that , , , Out with Well it to . great so Make in \" in . . 's Dialogue - the very , his the ,\n"
     ]
    }
   ],
   "source": [
    "stem = \"Such terrible acting\"\n",
    "pred = imdb_learn_0.predict(stem, n_words, temperature=0.8)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awful >.< These were way too little samples and training for such a model. However, with transfer learning, we have been able to obtain a somewhat decent model to make movie reviews. Of course, we saw that with more data and training the results are much better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon reviews\n",
    "\n",
    "Let's train now a model to generate amazon reviews. This is a much more challenging task provided that amazon reviews are, generally, awfully written and shorter. Sometimes, it seems that people completely forget that grammar exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.AMAZON_REVIEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = 5000\n",
    "a_df = pd.read_csv(path/\"train.csv\", names=[\"label\", \"title\", \"text\"]).sample(samples).reset_index()\n",
    "dls_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n",
    "                   get_x=ColReader('text'), splitter=RandomSplitter(0.1)\n",
    "                   ).dataloaders(a_df, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always have a look at the data! Let's see some reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj this book was great in it 's time , but only gets 4 stars as some characters are outdated . i do n't like to make a habit of giving any plot away , but what i will say is xxmaj stephen has a great way of getting the reader to visualize a situation . xxmaj there are situations in this book that as the reader you feel could happen</td>\n",
       "      <td>xxmaj this book was great in it 's time , but only gets 4 stars as some characters are outdated . i do n't like to make a habit of giving any plot away , but what i will say is xxmaj stephen has a great way of getting the reader to visualize a situation . xxmaj there are situations in this book that as the reader you feel could happen today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not enjoy anything about this xxup dvd it is rated r and that i must of overlooked because i never would of bought it . i began to watch about 5 minutes into the movie and threw it away . xxmaj it is poorly made the picture and sound is crazy . i watched the previews of the other movies the same company puts out and they were just as bad .</td>\n",
       "      <td>enjoy anything about this xxup dvd it is rated r and that i must of overlooked because i never would of bought it . i began to watch about 5 minutes into the movie and threw it away . xxmaj it is poorly made the picture and sound is crazy . i watched the previews of the other movies the same company puts out and they were just as bad . i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minutes than this does in 55 , and costs half as xxunk . xxbos xxmaj good xxunk . xxmaj good for people who do n't have everything . xxmaj these xxunk are of quality gaming value . xxmaj worth a look at the very least and worth the money . xxmaj no experience necessary . xxbos xxmaj enemy xxmaj engaged is a nice game . xxmaj the graphics look great and the</td>\n",
       "      <td>than this does in 55 , and costs half as xxunk . xxbos xxmaj good xxunk . xxmaj good for people who do n't have everything . xxmaj these xxunk are of quality gaming value . xxmaj worth a look at the very least and worth the money . xxmaj no experience necessary . xxbos xxmaj enemy xxmaj engaged is a nice game . xxmaj the graphics look great and the gameplay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our model, just as in the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.404650</td>\n",
       "      <td>4.037593</td>\n",
       "      <td>0.258091</td>\n",
       "      <td>56.689747</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.936937</td>\n",
       "      <td>3.920053</td>\n",
       "      <td>0.273897</td>\n",
       "      <td>50.403091</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.817908</td>\n",
       "      <td>3.886484</td>\n",
       "      <td>0.276378</td>\n",
       "      <td>48.739212</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.632674</td>\n",
       "      <td>3.889325</td>\n",
       "      <td>0.276664</td>\n",
       "      <td>48.877876</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.456472</td>\n",
       "      <td>3.901219</td>\n",
       "      <td>0.277141</td>\n",
       "      <td>49.462727</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amzn_learn.fine_tune(4, base_lr=2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hair dryer is expensive . The product does not work well well ! It is the first clean rock i ever bought and i love it ! i am not using my Hair Style Mixer , but i have had many Paltrow hair charms and i\n"
     ]
    }
   ],
   "source": [
    "stem = \"Hair dryer\"\n",
    "pred = amzn_learn.predict(stem, n_words, temperature=0.8)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was not sure about whether it was good or bad, but it does look like an amazon review about a hair dryer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "This is where you get creative. Compare the predictions of both models given the same starting points. You can play around and try to find ambiguous starting points, things that work in both contexts (movie reviews and product reviews), completely start deep into one field and see what the opposite model manages to output, etc.\n",
    "\n",
    "Have a bit of fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter never thinks of his best name . This is n't really a great story . It is a cute , awesome book that will start to grow like a book . It is just a novel , but i still have to read Harry Potter and\n",
      "\n",
      "Harry Potter never read the book ( when he was reading his book ) , upon seeing the book , i still thought it was an interesting film . Although it was not great enough to make any sense , the script was excellent . The acting was beautiful , and\n"
     ]
    }
   ],
   "source": [
    "stem = \"Harry Potter never \"\n",
    "pred_amzn = amzn_learn.predict(stem, n_words, temperature=0.8)\n",
    "pred_imdb = imdb_learn.predict(stem, n_words, temperature=0.8)\n",
    "print(pred_amzn+\"\\n\")\n",
    "print(pred_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, these reviews are not the best ever, but we can see how both know that Harry Potter are books so... I guess I'll take that. Copy/paste this bit of code and experiment a bit. Giving a longer starting point will make the prediction a little bit better. You can test and see what happens when we give it a long input or an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interesting phone mariah , it has been a success since . In the last few years we have tried a different model , but it 's too simple and does n't stay on it , so you want to tell my brother that she was a little too\n",
      "\n",
      "The British Channel channel ABC . It plays the island sitcom , The Shop on Earth . a local family shop is located on The Grande , and it has a British Food Agency named London\n"
     ]
    }
   ],
   "source": [
    "stem = \" \"\n",
    "pred_amzn = amzn_learn.predict(stem, n_words, temperature=0.8)\n",
    "pred_imdb = imdb_learn.predict(stem, n_words, temperature=0.8)\n",
    "print(pred_amzn+\"\\n\")\n",
    "print(pred_imdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
